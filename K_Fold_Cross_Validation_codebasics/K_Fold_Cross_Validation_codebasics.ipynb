{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to K Fold Cross Validation\n",
    "\n",
    "Link to the Youtube video tutorial: https://www.youtube.com/watch?v=gJo0uNL-5Qw&list=PLeo1K3hjS3uvCeTYTeyfe0-rN5r8zn9rw&index=13\n",
    "\n",
    "**Ways to train your machine learning model: K-fold cross validation technique**  <br />\n",
    "Theory behind k-fold cross validation:\n",
    "1) Firstly, we divide a dataset into folds(groups). In this example, we divide a dataset which consists of 100 samples into 5 folds(groups), each fold contains 20 samples (100/5=20). Then, you run multiple iterations. In the 1st iteration, you use fold number 2 to 5 as train set to train the model while fold number 1 (1st fold) as test set to test the model. Then, you note down the score.  <br />\n",
    "<img src=\"hidden\\cv1.png\" alt=\"This image describes k-fold cross validation tecnique, part 1\" style=\"width: 400px;\"/>  <br />\n",
    "\n",
    "2) In the 2nd iteration, you use fold number 1, 3, 4, and 5 as train set to train the model while fold number 2 (2nd fold) as test set to test the model. Then, you note down the score.  <br />\n",
    "<img src=\"hidden\\cv2.png\" alt=\"This image describes k-fold cross validation tecnique, part 2\" style=\"width: 400px;\"/>  <br />\n",
    "\n",
    "3) You repeat the process till the last fold where you use fold number 5 (5th fold) for testing and remaining folds for training.  <br />\n",
    "<img src=\"hidden\\cv3.png\" alt=\"This image describes k-fold cross validation tecnique, part 3\" style=\"width: 400px;\"/>  <br />\n",
    "\n",
    "4) Then, once you have the score from each iteration, you average them out.  <br />\n",
    "<img src=\"hidden\\cv4.png\" alt=\"This image describes k-fold cross validation tecnique, part 4\" style=\"width: 400px;\"/>  <br />\n",
    "\n",
    "5) K-fold cross validation technique is very good because you are giving variety of samples to your model and then you are taking individual scores and then averaging them out.\n",
    "\n",
    "6) Another detailed information with visualization of k-fold cross validation : https://www.statology.org/k-fold-cross-validation/\n",
    "\n",
    "Note:\n",
    "A classifier is basically your machine learning model which is trying to classify your samples\n",
    "\n",
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# load the dataset\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Encode the dependent variable\n",
    "Encode the categorical variables of the dependent variable from categorical names (text labels) into integer labels using label encoder. The encoded dependent variable is required by Stratified KFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target\n",
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "...      ...\n",
       "1792       9\n",
       "1793       0\n",
       "1794       8\n",
       "1795       9\n",
       "1796       8\n",
       "\n",
       "[1797 rows x 1 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# create a label encoder called le_DependentVariable\n",
    "le_DependentVariable = LabelEncoder() \n",
    "# encode the data available in the attribute of target of the dataset into integer labels. Then, save the outputs to variable called Y_encoded\n",
    "Y_encoded = le_DependentVariable.fit_transform(digits.target)\n",
    "\n",
    "import pandas as pd\n",
    "# show the encoded values for each data available in the attribute of target of the dataset, in the format of dataframe and manually set the column name as target.\n",
    "pd.DataFrame(Y_encoded,columns=['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the encoded dependent variable  <br />\n",
    "To check the output of Y_encoded by comparing with digits.target (Because the data available in digits.target are already in integer labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target\n",
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "...      ...\n",
       "1792       9\n",
       "1793       0\n",
       "1794       8\n",
       "1795       9\n",
       "1796       8\n",
       "\n",
       "[1797 rows x 1 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the data available in the attribute of target of the dataset, in the format of dataframe & its column name is manually set as target\n",
    "pd.DataFrame(digits.target,columns=['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-define a function to print performance metric of a machine learning model on the given test set after it is trained with the given train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a generic method (self-defined function) called get_score\n",
    "# the get_score takes model, train set, and test set as inputs\n",
    "def get_score(model, X_train, X_test, Y_train, Y_test):\n",
    "    # train the model\n",
    "    model.fit(X_train,Y_train) \n",
    "    # return/provide the score of the trained model\n",
    "    return model.score(X_test, Y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to KFold concept\n",
    "A simple example to introduce & explain KFold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8] [0 1 2]\n",
      "[0 1 2 6 7 8] [3 4 5]\n",
      "[0 1 2 3 4 5] [6 7 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIn this example:\\n[21,22,23,24,25,26,27,28,29] is the dataset provided to the kfold function (Usually the independent variables (features) are provided to the KFold as the dataset).\\nSince the dataset consists of total 9 samples, the indices (row numbers) of the dataset corresponding to the samples in the dataset are 0,1,2,3,4,5,6,7,8.\\nSince this kfold function will split the dataset into 3 folds (9 samples in dataset / 3 folds = 3 samples per fold).\\n1st fold contains the 3 indices (row numbers) of the dataset corresponding to the samples in the dataset -> [0,1,2]\\n2nd fold contains the 3 indices (row numbers) of the dataset corresponding to the samples in the dataset -> [3,4,5]\\n3rd fold contains the 3 indices (row numbers) of the dataset corresponding to the samples in the dataset -> [6,7,8]\\nThe 1st row of train_index contains indices (row numbers) of the dataset corresponding to the samples in the dataset for training the model (train set) in an iteration, \\nthe 1st row of test_index contains indices (row numbers) of the dataset corresponding to the samples in the dataset for testing the model (test set) in the same iteration.\\nSame concept applies to Nth row of train_index & test_index. In this example, since the KFold splits the dataset into 3 folds, the for loop of the KFold repeats for 3 iterations, the train_index & test_index have 3 rows eventually (1 row generated at each iteration of the for loop).\\n'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# create kfold function which will divide a dataset into 3 folds/groups (n_splits=3)\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in kf.split([21,22,23,24,25,26,27,28,29]):\n",
    "    print(train_index,test_index)\n",
    "\n",
    "'''\n",
    "In this example:\n",
    "[21,22,23,24,25,26,27,28,29] is the dataset provided to the kfold function (Usually the independent variables (features) are provided to the KFold as the dataset).\n",
    "Since the dataset consists of total 9 samples, the indices (row numbers) of the dataset corresponding to the samples in the dataset are 0,1,2,3,4,5,6,7,8.\n",
    "Since this kfold function will split the dataset into 3 folds (9 samples in dataset / 3 folds = 3 samples per fold).\n",
    "1st fold contains the 3 indices (row numbers) of the dataset corresponding to the samples in the dataset -> [0,1,2]\n",
    "2nd fold contains the 3 indices (row numbers) of the dataset corresponding to the samples in the dataset -> [3,4,5]\n",
    "3rd fold contains the 3 indices (row numbers) of the dataset corresponding to the samples in the dataset -> [6,7,8]\n",
    "The 1st row of train_index contains indices (row numbers) of the dataset corresponding to the samples in the dataset for training the model (train set) in an iteration, \n",
    "the 1st row of test_index contains indices (row numbers) of the dataset corresponding to the samples in the dataset for testing the model (test set) in the same iteration.\n",
    "Same concept applies to Nth row of train_index & test_index. In this example, since the KFold splits the dataset into 3 folds, the for loop of the KFold repeats for 3 iterations, the train_index & test_index have 3 rows eventually (1 row generated at each iteration of the for loop).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop machine learning models without cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preprocessing\n",
    "Split the dataset into train set and test set using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(digits.data, digits.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick way of measuring the performance of different machine learning models on the same train and test sets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (Logistic regression model) Create, train, and calculate the performance metric of logistic regression model in separate lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without cross validation, without involving self-defined function, the performance metric of the logistic regression model:  0.9703703703703703\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "\n",
    "# create a logistic regression model\n",
    "logistic_regression = LogisticRegression(max_iter=1000) # specify the max_iter parameter to avoid the warning\n",
    "# train the logistic regression model \n",
    "logistic_regression.fit(X_train,Y_train)\n",
    "# evaluate the performance of the trained logistic regression model \n",
    "lr_sl = logistic_regression.score(X_test,Y_test)\n",
    "\n",
    "print('Without cross validation, without involving self-defined function, the performance metric of the logistic regression model: ',lr_sl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (Logistic regression model) Create, train, and calculate the performance metric of logistic regression model using a single line (using self-defined function, get_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without cross validation, by involving self-defined function, the performance metric of the logistic regression model:  0.9703703703703703\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "lr_sdf = get_score(LogisticRegression(max_iter=1000), X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "print('Without cross validation, by involving self-defined function, the performance metric of the logistic regression model: ',lr_sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (SVM model) Create, train, and calculate the performance metric of SVM model in separate lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without cross validation, without involving self-defined function, the performance metric of the SVM model:  0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# SVM model\n",
    "\n",
    "# create a SVM model\n",
    "svm = SVC()\n",
    "# train the SVM model \n",
    "svm.fit(X_train,Y_train)\n",
    "# evaluate the performance of the trained SVM model \n",
    "svm_sl = svm.score(X_test,Y_test)\n",
    "\n",
    "print('Without cross validation, without involving self-defined function, the performance metric of the SVM model: ',svm_sl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (SVM model) Create, train, and calculate the performance metric of SVM model using a single line (using self-defined function, get_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without cross validation, by involving self-defined function, the performance metric of the SVM model:  0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# SVM model\n",
    "svm_sdf = get_score(SVC(), X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "print('Without cross validation, by involving self-defined function, the performance metric of the SVM model: ',svm_sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (Random forest model) Create, train, and calculate the performance metric of random forest model in separate lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without cross validation, without involving self-defined function, the performance metric of the random forest model:  0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "# Random forest model\n",
    "\n",
    "# create a random forest model\n",
    "random_forest = RandomForestClassifier()\n",
    "# train the random forest model \n",
    "random_forest.fit(X_train,Y_train)\n",
    "# evaluate the performance of the trained random model \n",
    "rf_sl = random_forest.score(X_test,Y_test)\n",
    "\n",
    "print('Without cross validation, without involving self-defined function, the performance metric of the random forest model: ',rf_sl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (Random forest model) Create, train, and calculate the performance metric of random forest model using a single line (using self-defined function, get_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without cross validation, by involving self-defined function, the performance metric of the random forest model:  0.9796296296296296\n"
     ]
    }
   ],
   "source": [
    "# Random forest model\n",
    "rf_sdf = get_score(RandomForestClassifier(), X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "print('Without cross validation, by involving self-defined function, the performance metric of the random forest model: ',rf_sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop machine learning models with cross validation using different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation with KFold to split a dataset into train and test sets + self-defined function to create, train, and calculate the performance metric of a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using KFold to split dataset into N folds, the performance metric of different machine learning models:\n",
      "Logistic regression model\t:[0.9248747913188647, 0.9432387312186978, 0.9148580968280468]\n",
      "SVM model\t\t\t:[0.9666110183639399, 0.9816360601001669, 0.9549248747913188]\n",
      "Random forest model\t\t:[0.9382303839732888, 0.9565943238731218, 0.9282136894824707]\n"
     ]
    }
   ],
   "source": [
    "# create an empty variable to store the performance metric of logistic regression model for different folds of dataset as test set later\n",
    "scores_logis_kf = [] \n",
    "# create an empty variable to store the performance metric of SVM model for different folds of dataset as test set later\n",
    "scores_svm_kf = []\n",
    "# create an empty variable to store the performance metric of random forest model for different folds of dataset as test set later\n",
    "scores_randforest_kf = []\n",
    "\n",
    "## Divide/split the dataset into N folds using KFold\n",
    "# KFold only requires either independent variable or dependent variable as input to get the size of samples available in the dataset, then split the dataset into N fold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# create KFold object that will divide/split a dataset into 3 folds (n_splits=3)\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "# split the dataset into 3 folds (the for loop will iterate 3 times)\n",
    "for train_index_kf, test_index_kf in kf.split(digits.data):\n",
    "    # the train_index_kf & test_index_kf have 3 rows eventually (1 row generated at each iteration of the for loop).\n",
    "    # The 1st row of train_index_kf contains indices (row numbers) of the dataset corresponding to the samples in the dataset for training the model (train set) in an iteration, \n",
    "    # the 1st row of test_index_kf contains indices (row numbers) of the dataset corresponding to the samples in the dataset for testing the model (test set) in the same iteration.\n",
    "    # Same concept applies to Nth row of train_index_kf & test_index_kf. So we use the indices in train_index_kf to identify the \n",
    "    # samples (data of independent and dependent variables) of the dataset which will be used to train the machine learning model (train set), then load them into X_train_kf and X_test_kf variables respectively. Same concept applies to test set.\n",
    "    X_train_kf, X_test_kf, Y_train_kf, Y_test_kf = digits.data[train_index_kf], digits.data[test_index_kf], \\\n",
    "                                                   Y_encoded[train_index_kf], Y_encoded[test_index_kf]\n",
    "    \n",
    "    '''\n",
    "    Create, train, and calculate the performance metric of logistic regression model using a single line (using self-defined function, get_score). \n",
    "    Then, append the performance metric of logistic regression model for different folds of dataset as test set to scores_logis_kf variable.\n",
    "    '''\n",
    "    scores_logis_kf.append(get_score(LogisticRegression(max_iter=1000),X_train_kf,X_test_kf,Y_train_kf,Y_test_kf))\n",
    "    '''\n",
    "    Create, train, and calculate the performance metric of SVM model using a single line (using self-defined function, get_score). \n",
    "    Then, append the performance metric of SVM model for different folds of dataset as test set to scores_svm_kf variable.\n",
    "    '''\n",
    "    scores_svm_kf.append(get_score(SVC(),X_train_kf,X_test_kf,Y_train_kf,Y_test_kf))\n",
    "    '''\n",
    "    Create, train, and calculate the performance metric of random forest model using a single line (using self-defined function, get_score). \n",
    "    Then, append the performance metric of random forest model for different folds of dataset as test set to scores_rf_kf variable.\n",
    "    '''\n",
    "    scores_randforest_kf.append(get_score(RandomForestClassifier(),X_train_kf,X_test_kf,Y_train_kf,Y_test_kf))\n",
    "\n",
    "# show the performance metric of different machine learning models\n",
    "print('Using KFold to split dataset into N folds, the performance metric of different machine learning models:\\nLogistic regression model\\t:'\\\n",
    "      +str(scores_logis_kf)+'\\nSVM model\\t\\t\\t:'+str(scores_svm_kf)+'\\nRandom forest model\\t\\t:'+str(scores_randforest_kf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation with Stratified KFold to split a dataset into train and test sets + self-defined function to create, train, and calculate the performance metric of a machine learning model\n",
    "\n",
    "Parameters of cross_val_score:\n",
    "<img src=\"hidden\\crossvalscore.png\" alt=\"This image describes cross_val_score parameters\" style=\"width: 400px;\"/>  <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using StratifiedKFold to split dataset into N folds, the performance metric of different machine learning models:\n",
      "Logistic regression model\t:[0.9198664440734557, 0.9415692821368948, 0.9165275459098498]\n",
      "SVM model\t\t\t:[0.9649415692821369, 0.9799666110183639, 0.9649415692821369]\n",
      "Random forest model\t\t:[0.9382303839732888, 0.9649415692821369, 0.9181969949916527]\n"
     ]
    }
   ],
   "source": [
    "# create an empty variable to store the performance metric of logistic regression model for different folds of dataset as test set later\n",
    "scores_logis_kf_stratified = [] \n",
    "# create an empty variable to store the performance metric of SVM model for different folds of dataset as test set later\n",
    "scores_svm_kf_stratified = []\n",
    "# create an empty variable to store the performance metric of random forest model for different folds of dataset as test set later\n",
    "scores_randforest_kf_stratified = []\n",
    "\n",
    "## Divide/split the dataset into N folds using StratifiedKFold\n",
    "# Advantage of StratifiedKFold over KFold: it will divide each of the classification categories available in the dataset in a uniform way. So using StratifiedKFold is better.\n",
    "# StratifiedKFold also requires dependent variable as input whose data are encoded into integer labels so that it can divide each of the classification categories available in the dataset in a uniform way.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# create a StratifiedKFold object that will divide/split a dataset into 3 folds (n_splits=3)\n",
    "kf_stratified = StratifiedKFold(n_splits=3) \n",
    "\n",
    "# split the dataset into 3 folds (the for loop will iterate 3 times)\n",
    "for train_index_kf_stratified, test_index_kf_stratified in kf_stratified.split(digits.data,Y_encoded):\n",
    "    # the train_index_kf_stratified & test_index_kf_stratified have 3 rows eventually (1 row generated at each iteration of the for loop).\n",
    "    # The 1st row of train_index_kf_stratified contains indices (row numbers) of the dataset corresponding to the samples in the dataset for training the model (train set) in an iteration, \n",
    "    # the 1st row of test_index_kf_stratified contains indices (row numbers) of the dataset corresponding to the samples in the dataset for testing the model (test set) in the same iteration.\n",
    "    # Same concept applies to Nth row of train_index_kf_stratified & test_index_kf_stratified. So we use the indices in train_index_kf_stratified to identify the \n",
    "    # samples (data of independent and dependent variables) of the dataset which will be used to train the machine learning model (train set), then load them into X_train_kf_stratified and X_test_kf_stratified variables respectively. Same concept applies to test set.\n",
    "    X_train_kf_stratified, X_test_kf_stratified, Y_train_kf_stratified, Y_test_kf_stratified = digits.data[train_index_kf_stratified], digits.data[test_index_kf_stratified], \\\n",
    "                                                                                                Y_encoded[train_index_kf_stratified], Y_encoded[test_index_kf_stratified]\n",
    "    \n",
    "    '''\n",
    "    Create, train, and calculate the performance metric of logistic regression model using a single line (using self-defined function, get_score). \n",
    "    Then, append the performance metric of logistic regression model for different folds of dataset as test set to scores_logis_kf_stratified variable.\n",
    "    '''\n",
    "    scores_logis_kf_stratified.append(get_score(LogisticRegression(max_iter=1000),X_train_kf_stratified,X_test_kf_stratified,Y_train_kf_stratified,Y_test_kf_stratified))\n",
    "    '''\n",
    "    Create, train, and calculate the performance metric of SVM model using a single line (using self-defined function, get_score). \n",
    "    Then, append the performance metric of SVM model for different folds of dataset as test set to scores_svm_kf_stratified variable.\n",
    "    '''\n",
    "    scores_svm_kf_stratified.append(get_score(SVC(),X_train_kf_stratified,X_test_kf_stratified,Y_train_kf_stratified,Y_test_kf_stratified))\n",
    "    '''\n",
    "    Create, train, and calculate the performance metric of random forest model using a single line (using self-defined function, get_score). \n",
    "    Then, append the performance metric of random forest model for different folds of dataset as test set to scores_rf_kf_stratified variable.\n",
    "    '''\n",
    "    scores_randforest_kf_stratified.append(get_score(RandomForestClassifier(),X_train_kf_stratified,X_test_kf_stratified,Y_train_kf_stratified,Y_test_kf_stratified))\n",
    "\n",
    "# show the performance metric of different machine learning models\n",
    "print('Using StratifiedKFold to split dataset into N folds, the performance metric of different machine learning models:\\nLogistic regression model\\t:'\\\n",
    "      +str(scores_logis_kf_stratified)+'\\nSVM model\\t\\t\\t:'+str(scores_svm_kf_stratified)+'\\nRandom forest model\\t\\t:'+str(scores_randforest_kf_stratified))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation with cross_val_score to split a dataset into train and test sets + create, train, and calculate the performance metric of a machine learning model (without self-defined function to print performance metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cross_val_score to split dataset into N folds then create, train, and calculate the performance metric of a machine learning model , the performance metric of different machine learning models:\n",
      "Logistic regression model\t:[0.91986644 0.94156928 0.91652755]\n",
      "SVM model\t\t\t:[0.96494157 0.97996661 0.96494157]\n",
      "Random forest model\t\t:[0.93489149 0.96661102 0.92988314]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "'''\n",
    "split the dataset into 3 folds, then get the performance metric of logistic regression model for different folds of dataset as test set. \n",
    "Store the outputs to lr_cvs variable. The data available in the attribute of data of the dataset is provided as independent variables,\n",
    "while the data available in the attribute of target of the dataset is provided as dependent variables. The parameter of cv refers to the \n",
    "number of folds/groups the dataset will be splitted into.\n",
    "'''\n",
    "lr_cvs = cross_val_score(LogisticRegression(max_iter=1000),digits.data,digits.target,cv=3)\n",
    "\n",
    "'''\n",
    "split the dataset into 3 folds, then get the performance metric of SVM model for different folds of dataset as test set. \n",
    "Store the outputs to lr_cvs variable. The data available in the attribute of data of the dataset is provided as independent variables,\n",
    "while the data available in the attribute of target of the dataset is provided as dependent variables. The parameter of cv refers to the \n",
    "number of folds/groups the dataset will be splitted into.\n",
    "'''\n",
    "svm_cvs = cross_val_score(SVC(),digits.data,digits.target,cv=3)\n",
    "\n",
    "'''\n",
    "split the dataset into 3 folds, then get the performance metric of random forest model for different folds of dataset as test set. \n",
    "Store the outputs to lr_cvs variable. The data available in the attribute of data of the dataset is provided as independent variables,\n",
    "while the data available in the attribute of target of the dataset is provided as dependent variables. The parameter of cv refers to the \n",
    "number of folds/groups the dataset will be splitted into.\n",
    "'''\n",
    "rf_cvs = cross_val_score(RandomForestClassifier(),digits.data,digits.target,cv=3)\n",
    "\n",
    "# show the performance metric of different machine learning models\n",
    "print('Using cross_val_score to split dataset into N folds then create, train, and calculate the performance metric of a machine learning model , the performance metric of different machine learning models:\\nLogistic regression model\\t:'\\\n",
    "      +str(lr_cvs)+'\\nSVM model\\t\\t\\t:'+str(svm_cvs)+'\\nRandom forest model\\t\\t:'+str(rf_cvs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
