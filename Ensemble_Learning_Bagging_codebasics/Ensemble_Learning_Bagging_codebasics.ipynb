{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning-Bagging\n",
    "\n",
    "Link to the Youtube tutorial video: https://www.youtube.com/watch?v=RtrBtAKwcxQ&list=PLeo1K3hjS3uvCeTYTeyfe0-rN5r8zn9rw&index=22&t=361s\n",
    "\n",
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if any column of the dataset consists of missing values (NA/NaN)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the basic statistics for each of the columns of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n",
      "The ratio of dependent variable data of the dataset: 0.536\n"
     ]
    }
   ],
   "source": [
    "# check if the data of dependent variable (Outcome column) of the dataset is imbalanced (EG: the number of 0 is not equal to the number of 1) \n",
    "print(df.Outcome.value_counts())\n",
    "\n",
    "# the output show there are 500 samples with outcome of 0; 268 samples with outcome of 1.\n",
    "\n",
    "ratio = df.Outcome.value_counts()[1]/df.Outcome.value_counts()[0]\n",
    "print('The ratio of dependent variable data of the dataset: '+str(ratio))\n",
    "# the ratio is 0.536 (around 2:1 ratio). It looks like slight imbalance but it is not a major imbalanceeee. Major imbalance would be like 10:1 or 100:1 ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the independent variables of the dataset to X variable\n",
    "X = df.drop('Outcome',axis='columns')\n",
    "\n",
    "# load the dependent variable of the dataset to Y variable\n",
    "Y = df.Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the features (independent variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63994726,  0.84832379,  0.14964075,  0.90726993, -0.69289057,\n",
       "         0.20401277,  0.46849198,  1.4259954 ],\n",
       "       [-0.84488505, -1.12339636, -0.16054575,  0.53090156, -0.69289057,\n",
       "        -0.68442195, -0.36506078, -0.19067191],\n",
       "       [ 1.23388019,  1.94372388, -0.26394125, -1.28821221, -0.69289057,\n",
       "        -1.10325546,  0.60439732, -0.10558415]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since the maximum value of each feature (independent variable) are not the same, means they are on a different scale. Just to be on a safe side, you scale those features.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a StandardScaler as the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the features and save them to X_scaled variable\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# show the first 3 rows of the X_scaled variable\n",
    "X_scaled[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into train and test sets using train_test_split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set consists of 576 samples\n",
      "The test set consists of 192 samples\n",
      "\n",
      "The ratio of dependent variable data in train set: 0.536\n",
      "The ratio of dependent variable data in test set: 0.536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "'''\n",
    "Since the dependent variable data of the dataset is slightly imbalanced, you use stratify\n",
    "to ensure the samples in the test and train sets maintains the ratio calculated above respectively.\n",
    "The random_state is specified to allow the reproducibility (means every time you run train_test_split, you get the same train and test sets).\n",
    "'''\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, stratify=Y, random_state=10)\n",
    "\n",
    "print('The train set consists of '+str(Y_train.shape[0])+' samples\\nThe test set consists of '+str(Y_test.shape[0])+' samples\\n')\n",
    "\n",
    "print('The ratio of dependent variable data in train set: '+str(Y_train.value_counts()[1]/Y_train.value_counts()[0]))\n",
    "print('The ratio of dependent variable data in test set: '+str(Y_test.value_counts()[1]/Y_test.value_counts()[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop the machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alone, with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model at each iteration of cross validation:  [0.68181818 0.68181818 0.66883117 0.79084967 0.69281046]\n",
      "The final/mean accuracy of the model from the cross validation:  0.7032255326372973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(DecisionTreeClassifier(), X_scaled, Y, cv=5)\n",
    "print('The accuracy of the model at each iteration of cross validation: ',scores)\n",
    "\n",
    "print('The final/mean accuracy of the model from the cross validation: ',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bagging Classifier, with Decision Tree Classifier as the base estimator\n",
    "\n",
    "Explanation of the Bagging Classifier parameters (16:35 -> 20:07): https://www.youtube.com/watch?v=RtrBtAKwcxQ&list=PLeo1K3hjS3uvCeTYTeyfe0-rN5r8zn9rw&index=22&t=361s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Out-of-Bag (OOB) score of the trained Bagging Classifier:  0.7534722222222222\n",
      "The score of the trained Bagging Classifier:  0.7760416666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFindings:\\nThe base model (by using a decision tree classifier alone) gives lower accuracy while the bagged model (by using decision tree classifier as base estimator model)\\ngives higher accuracy. So for unstable classifier like decision tree classifier, the bagging technique helps.\\nIf you have an unstable classifier OR your dataset consists of many missing values, your resulting model has high variance.\\nAnd whenever you have high variance, it makes sense to use bagging classifier.\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# create the Bagging Classifier\n",
    "bag_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=100,\n",
    "    max_samples=0.8,\n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# train the Bagging Classifier\n",
    "bag_model.fit(X_train,Y_train)\n",
    "\n",
    "# Here, the OOB score is not computed based on the samples in X_test and Y_test, just using the samples in train set which are not found in the 100 subsets sampled from X_train.\n",
    "print('The Out-of-Bag (OOB) score of the trained Bagging Classifier: ',bag_model.oob_score_)\n",
    "\n",
    "print('The score of the trained Bagging Classifier: ',bag_model.score(X_test,Y_test))\n",
    "\n",
    "'''\n",
    "Findings:\n",
    "The base model (by using a decision tree classifier alone) gives lower accuracy while the bagged model (by using decision tree classifier as base estimator model)\n",
    "gives higher accuracy. So for unstable classifier like decision tree classifier, the bagging technique helps.\n",
    "If you have an unstable classifier OR your dataset consists of many missing values, your resulting model has high variance.\n",
    "And whenever you have high variance, it makes sense to use bagging classifier.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model at each iteration of cross validation:  [0.75324675 0.72727273 0.74675325 0.82352941 0.74509804]\n",
      "The final/mean accuracy of the model from the cross validation:  0.7591800356506239\n"
     ]
    }
   ],
   "source": [
    "# create the Bagging Classifier\n",
    "bag_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=100,\n",
    "    max_samples=0.8,\n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "scores = cross_val_score(bag_model, X_scaled, Y, cv=5)\n",
    "print('The accuracy of the model at each iteration of cross validation: ',scores)\n",
    "\n",
    "print('The final/mean accuracy of the model from the cross validation: ',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Random Forest Classifier alone, with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final/mean accuracy of the model from the cross validation:  0.7617944147355913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFindings:\\nThe random forest classifier gives score similar to the one of bagging classfier with decision tree classifier as base estimator.\\nThis is because inside the random forest classifier, it will use bagging technique, similar to the theory behind the bagging classifier.\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "scores = cross_val_score(RandomForestClassifier(), X_scaled, Y, cv=5)\n",
    "\n",
    "print('The final/mean accuracy of the model from the cross validation: ',scores.mean())\n",
    "\n",
    "'''\n",
    "Findings:\n",
    "The random forest classifier gives score similar to the one of bagging classfier with decision tree classifier as base estimator.\n",
    "This is because inside the random forest classifier, it will use bagging technique, similar to the theory behind the bagging classifier.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
